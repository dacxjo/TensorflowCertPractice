{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Copyright (c) 2023, Troy Phat Tran (Mr. Troy).<br>\n", "Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset, which is a derivative work from original NIST<br>\n", "datasets. MNIST dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Question:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a classifier for the MNIST dataset which includes black-and-white images of 10 digits (0-9). The input shape<br>\n", "should be (28, 28, 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Your task is to fill in the missing parts of the code block (where commented as \"ADD CODE HERE\")."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import tensorflow_datasets as tfds\n", "from keras import Sequential\n", "from keras.callbacks import EarlyStopping\n", "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n", "from keras.saving import load_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use Tensorflow datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def my_model():\n", "    # Load the MNIST dataset\n", "    (train_ds, valid_ds), info = tfds.load(name='mnist', split=['train', 'test'], with_info=True, as_supervised=True)\n\n", "    # Preprocess the training data\n", "    train_ds = train_ds.map(normalize).cache().shuffle(info.splits['train'].num_examples).batch(32).prefetch(\n", "        buffer_size=tf.data.AUTOTUNE)\n\n", "    # Preprocess the test data\n", "    valid_ds = valid_ds.map(normalize).cache().batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n\n", "    # Define the model architecture\n", "    model = Sequential([\n", "        # ADD CODE HERE\n", "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n", "        MaxPooling2D((2, 2)),\n", "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n", "        MaxPooling2D((2, 2)),\n", "        Flatten(),\n", "        Dense(units=64, activation='relu'),\n", "        Dense(units=10, activation='softmax')\n", "    ])\n\n", "    # Compile the model\n", "    # ADD CODE HERE\n", "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n", "    # Define the early stopping callback\n", "    # ADD CODE HERE\n", "    early_stop = EarlyStopping(monitor='val_accuracy', patience=5, min_delta=0.01, verbose=1)\n\n", "    # Train the model\n", "    # ADD CODE HERE\n", "    model.fit(x=train_ds, epochs=10, validation_data=valid_ds, callbacks=[early_stop])\n", "    return model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A function to normalize the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def normalize(image, label):\n", "    return tf.cast(x=image, dtype=tf.float32) / 255.0, label"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===============DO NOT EDIT THIS PART================================"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    # Run and save your model\n", "    my_model = my_model()\n", "    filepath = \"grayscale_model_2.h5\"\n", "    my_model.save(filepath)\n\n", "    # Reload the saved model\n", "    saved_model = load_model(filepath)\n\n", "    # Show the model architecture\n", "    saved_model.summary()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}