{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2023, Troy Phat Tran (Mr. Troy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train a Sequential model that can predict the level of humidity for My City using the my-city-humidity.csv<br>\n",
    "dataset. In this particular problem, we only need to predict the sunspot activity based on the previous values of the<br>\n",
    "series not the time steps, so you don't need to include the time step as a feature in the model. The normalized<br>\n",
    "dataset should have a mean absolute error (MAE) of 0.15 or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to fill in the missing parts of the code block (where commented as \"ADD CODE HERE\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.saving import load_model\n",
    "from keras.src.utils.data_utils import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences_model():\n",
    "    # Download the dataset\n",
    "    csv_file = 'my-city-humidity.csv'\n",
    "    if not os.path.exists(csv_file):\n",
    "        url = 'https://trientran.github.io/tf-practice-exams/my-city-humidity.csv'\n",
    "        urlretrieve(url=url, filename=csv_file)\n",
    "    humidity = []\n",
    "\n",
    "    # Read the CSV and append all the records to humidity\n",
    "    with open(csv_file) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            humidity.append(float(row[2]))\n",
    "    series = np.array(humidity)\n",
    "\n",
    "    # Normalize the data\n",
    "    min_value = np.min(series)\n",
    "    max_value = np.max(series)\n",
    "    series -= min_value\n",
    "    series /= max_value\n",
    "\n",
    "    # The data is split into training and validation sets at time step 2900 (~90% of the number of records). When it\n",
    "    # comes to the real test, the dataset may be bigger or smaller than this dataset. They may have already set this\n",
    "    # value for you or you must calculate it yourself.\n",
    "    split_step = 2900\n",
    "\n",
    "    # In this particular problem, we only need to predict the sunspot activity based on the previous values of the\n",
    "    # series, so we don't need to include the time step as a feature in the model. Therefore, we only use the x_train\n",
    "    # and x_valid variables (not time_train nor time_valid), which contain the normalized sunspot activity values for\n",
    "    # the training and validation sets.\n",
    "    x_train = series[:split_step]\n",
    "    x_valid = series[split_step:]\n",
    "\n",
    "    # Some default constants\n",
    "    shuffle_buffer = 1000\n",
    "    batch_size = 32\n",
    "    window_size = 30\n",
    "    train_set = windowed_dataset(\n",
    "        series=x_train,\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer=shuffle_buffer\n",
    "    )\n",
    "    valid_set = windowed_dataset(\n",
    "        series=x_valid,\n",
    "        window_size=window_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer=shuffle_buffer\n",
    "    )\n",
    "\n",
    "    # Define your model\n",
    "    model = Sequential([\n",
    "        # ADD CODE HERE\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    # ADD CODE HERE\n",
    "\n",
    "    # Optional: Define early stopping callbacks.\n",
    "    # ADD CODE HERE\n",
    "\n",
    "    # Train the model\n",
    "    # ADD CODE HERE\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are aiming at achieving a certain limit of Mean Absolute Error, this callback class will be handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        val_mae = logs.get('val_mae')\n",
    "        # Very importantly, you must change this number if the test expects a certain limit of MAE.For example, this\n",
    "        # test requires an MAE of 0.15 or less. So it makes sense to set this number to 0.15\n",
    "        if val_mae <= 0.15:\n",
    "            print(f\"\\nReached {val_mae} Mean Absolute Error after {epoch} epochs so stopping training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet is copied from<br>\n",
    "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP/S%2BP%20Week%204%20Exercise%20Answer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size=window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===============DO NOT EDIT THE BELOW================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Run and save your model\n",
    "    my_model = sequences_model()\n",
    "    filepath = \"sequences_model.h5\"\n",
    "    my_model.save(filepath)\n",
    "\n",
    "    # Reload the saved model\n",
    "    saved_model = load_model(filepath)\n",
    "\n",
    "    # Show the model architecture\n",
    "    saved_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
