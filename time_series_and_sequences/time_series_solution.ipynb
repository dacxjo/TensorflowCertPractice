{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Copyright (c) 2023, Troy Phat Tran (Mr. Troy)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Question:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Build and train a Sequential model that can predict the level of humidity for 5 cities over the time using the<br>\n", "cities-humidity.csv dataset. The normalized dataset should have a mean absolute error (MAE) of 0.15 or less."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Your task is to fill in the missing parts of the code block (where commented as \"ADD CODE HERE\")."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Specific requirements:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1. Input shape: (batch_size = 8, n_past = 6, n_features = 5)<br>\n", "   n_past means a window of the past 6 observations<br>\n", "   n_features means 5 features (cities) to predict"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2. Output shape: (batch_size = 8, n_future = 6, n_features = 5)<br>\n", "   n_future means the next 6 observations to predict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from urllib.request import urlretrieve"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from keras import Sequential\n", "from keras.callbacks import EarlyStopping, Callback\n", "from keras.src.layers import Bidirectional, LSTM, Dense, Reshape\n", "from keras.src.saving.saving_api import load_model\n", "from tensorflow.python.data import Dataset\n", "from tensorflow.python.framework.random_seed import set_seed"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def time_series_model():\n", "    # Download the dataset\n", "    csv_file = 'cities-humidity.csv'\n", "    if not os.path.exists(csv_file):\n", "        url = 'https://trientran.github.io/tf-practice-exams/cities-humidity.csv'\n", "        urlretrieve(url=url, filename=csv_file)\n\n", "    # Read the CSV\n", "    df = pd.read_csv(csv_file, sep=',', index_col='date', header=0)\n\n", "    # Normalize the data\n", "    data = df.values\n", "    data = data - data.min(axis=0)\n", "    data = data / data.max(axis=0)\n\n", "    # Define a variable to hold the number of features/cities in the dataset.\n", "    n_features = len(df.columns)\n\n", "    # Some default constants (feel free to update these if the real exam provides different ones)\n", "    n_past = 6\n", "    n_future = 6\n", "    batch_size = 8\n\n", "    # Set seed to persist training results\n", "    set_seed(1)\n\n", "    # Split into training and validation sets.\n", "    split_time = int(len(data) * 0.5)\n", "    x_train = data[:split_time]\n", "    x_valid = data[split_time:]\n\n", "    # Create windowed train and validation sets\n", "    train_set = windowed_dataset(series=x_train, batch_size=batch_size, n_past=n_past, n_future=n_future)\n", "    valid_set = windowed_dataset(series=x_valid, batch_size=batch_size, n_past=n_past, n_future=n_future)\n\n", "    # Define your model\n", "    model = Sequential([\n", "        # ADD CODE HERE\n", "        Bidirectional(LSTM(32, return_sequences=True, input_shape=(n_past, n_features))),\n", "        Bidirectional(LSTM(32)),\n", "        Dense(n_features * n_future, activation='relu'),\n", "        Reshape((n_future, n_features)),\n", "    ])\n\n", "    # Compile the model\n", "    # ADD CODE HERE\n", "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n\n", "    # Build the model and print out summary log to double-check input and output shapes\n", "    # ADD CODE HERE\n", "    model.build(input_shape=(batch_size, n_past, n_features))\n", "    model.summary()\n", "    input_shape = model.layers[0].input_shape\n", "    print(f'Input shape: {input_shape}')\n\n", "    # Define callbacks\n", "    # ADD CODE HERE\n", "    early_stopping_1 = EarlyStopping(monitor='val_mae', mode='min', patience=10, verbose=1, min_delta=0.005)  # optional\n", "    early_stopping_2 = MyCallback()\n\n", "    # Trains the model\n", "    # ADD CODE HERE\n", "    model.fit(train_set, epochs=1000, validation_data=valid_set, callbacks=[early_stopping_2])\n", "    # model.fit(train_set, epochs=1000, validation_data=valid_set, callbacks=[early_stopping_1, early_stopping_2])\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MyCallback(Callback):\n", "    def on_epoch_end(self, epoch, logs=None):\n", "        if logs is None:\n", "            logs = {}\n", "        val_mae = logs.get('val_mae')\n", "        if val_mae <= 0.15:  # Very importantly, you must change this number if the test expects a certain limit of MAE.\n", "            # For example, this test requires an MAE of 0.15 or less. So it makes sense to set this number to 0.15\n", "            print(f\"\\nReached {val_mae} Mean Absolute Error after {epoch} epochs so stopping training!\")\n", "            self.model.stop_training = True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A function to create windowed dataset. Derived from<br>\n", "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP/S%2BP%20Week%204%20Exercise%20Answer.ipynb"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def windowed_dataset(series, batch_size, n_past, n_future):\n", "    ds = Dataset.from_tensor_slices(series)\n", "    ds = ds.window(size=n_past + n_future, shift=1, drop_remainder=True)\n", "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n", "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n", "    return ds.batch(batch_size).prefetch(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["===============DO NOT EDIT THE BELOW================================<br>\n", "Train and save the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    # Run and save your model\n", "    my_model = time_series_model()\n", "    filepath = \"time_series_model.h5\"\n", "    my_model.save(filepath)\n\n", "    # Reload the saved model\n", "    saved_model = load_model(filepath)\n\n", "    # Show the model architecture\n", "    saved_model.summary()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}